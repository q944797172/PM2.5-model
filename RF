#-*- coding: utf-8 -*-
##导入包
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import math
from pandas.core.common import random_state
from scipy.stats import gaussian_kde
from sklearn.ensemble import RandomForestRegressor
import matplotlib.pyplot as plt
import matplotlib
from sklearn.model_selection import train_test_split
import pickle
from sklearn.model_selection import KFold

def scatter_plot(TureValues,PredictValues):
    #设置参考的1：1虚线参数
    xxx = [-100.5,500.5]
    yyy = [-100.5,500.5]
    T_m=round(max(TureValues))
    P_m=round(max(PredictValues))
    xy = np.vstack([TureValues, PredictValues])
    z = gaussian_kde(xy)(xy)
    #绘图
    plt.figure()
    font1 = {'family': 'Times New Roman',
             'weight': 'bold',
             'size': 18,
             }

    plt.subplots_adjust(left=0.15, right=0.95, top=0.95, bottom=0.15)
    plt.tick_params(labelsize=16)
    plt.plot(xxx , yyy , c='0' , linewidth=1 , linestyle=':' , marker='.' , alpha=0.4)#绘制虚线
    # plt.scatter(TureValues , PredictValues , s=20 , c='r' , edgecolors='k' , marker='o' , alpha=0.8,cmap='Spectral')#绘制散点图，横轴是真实值，竖轴是预测值
    plt.scatter(TureValues, PredictValues, s=20, c=z,cmap='Spectral')  # 绘制散点图，横
    plt.xlim((0,300))   #设置坐标轴范围
    plt.ylim((0,300))
    # plt.figure(figsize=(10, 8), dpi=100)
    plt.xlabel("Actual value (μg/m³)",font1)
    # 设置y轴的文本，用于描述y轴代表的是什么
    plt.ylabel("Predictive value (μg/m³)",font1)
    plt.title('')
    plt.show()

'''对数据进行统计分析，查看数据的分布情况'''
data=pd.read_excel('汇总数据9.6.xlsx',index_col=0)
# data=pd.read_excel('十折训练.xlsx',index_col=0)
print (data.head())
print (data.shape)

index=data.index
col=data.columns
class_names=np.unique(data.iloc[:,1])
print (type(data))
print (class_names)
#print (data.describe())


'''划分训练集和验证集'''
#radom_state编辑
data_train, data_test= train_test_split(data,test_size=0.2,random_state=0)

print ("训练集统计描述：\n",data_train.describe().round(2))
print ("验证集统计描述：\n",data_test.describe().round(2))
print ("训练集信息：\n",data_train.iloc[:,-1].value_counts())
print ("验证集信息：\n",data_test.iloc[:,-1].value_counts())





'''构建随机森林回归模型'''
#获取训练集和验证集不带分区信息
X_train=data_train.iloc[:,1:-1]
X_test=data_test.iloc[:,1:-1]
feature=data_train.iloc[:,1:-1].columns
print (feature)
y_train=data_train.iloc[:,-1]
y_test=data_test.iloc[:,-1]

#获取训练集和验证集带分区信息
# X_train=data_train.iloc[:,0:-3]
# X_test=data_test.iloc[:,0:-3]
# feature=data_train.iloc[:,0:-3].columns
# print (feature)
# y_train=data_train.iloc[:,-3]
# y_test=data_test.iloc[:,-3]
#print (y_test_reg)


'''模型调参'''
##参数选择
from sklearn.model_selection import RandomizedSearchCV
criterion=['mse','mae']
n_estimators = [int(x) for x in np.linspace(start = 500, stop =3000, num = 500)]
max_features = ['auto', 'sqrt']
max_depth = [int(x) for x in np.linspace(20, 60, num = 10)]
max_depth.append(None)
min_samples_split = [2, 5, 10]
min_samples_leaf = [1, 2, 4]
bootstrap = [True, False]
random_grid = {'criterion':criterion,
                'n_estimators': n_estimators,
               'max_features': max_features,
               'max_depth': max_depth,
               'min_samples_split': min_samples_split,
               'min_samples_leaf': min_samples_leaf,
               'bootstrap': bootstrap}
#构建模型
clf= RandomForestRegressor()
clf_random = RandomizedSearchCV(estimator=clf, param_distributions=random_grid,
                              n_iter = 10,
                              cv = 3, verbose=2, random_state=42, n_jobs=-1)
#回归
clf_random.fit(X_train, y_train)
print (clf_random.best_params_)


'''模型训练、验证、评估'''
from pyecharts import Bar
rf=RandomForestRegressor(criterion='mse',bootstrap=False,max_features='sqrt', max_depth=30,min_samples_split=10, n_estimators=2000,min_samples_leaf=2)

rf.fit(X_train, y_train)
y_train_pred=rf.predict(X_train)
y_test_pred=rf.predict(X_test)

#指标重要性
print (rf.feature_importances_)
bar=Bar()
bar.add('指标重要性',feature, rf.feature_importances_.round(3),is_label_show=True,label_text_color='#000')
bar.render('指标重要性.html')

from sklearn.metrics import mean_squared_error,explained_variance_score,mean_absolute_error,r2_score
'生成散点图'
scatter_plot(y_train,y_train_pred)

print ('R2:',rf.score(X_train,y_train))
print ('均方差',mean_squared_error(y_train,y_train_pred))
print ('绝对差',mean_absolute_error(y_train,y_train_pred))
print ('解释度',explained_variance_score(y_train,y_train_pred))


print ('R2:',rf.score(X_test,y_test))
print ('均方差',mean_squared_error(y_test,y_test_pred))
print ('绝对差',mean_absolute_error(y_test,y_test_pred))
print ('解释度',explained_variance_score(y_test,y_test_pred))

pickle.dump(rf,open("dtrhvg.dat","wb"))

