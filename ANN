
import math
import os
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error, r2_score

import tensorflow as tf
import pandas as pd
from keras.models import Sequential				
from keras.layers import Dense,Dropout			
from keras.optimizers import Adam				ss 
import matplotlib.pyplot as plt
from opt_einsum.backends import torch
from scipy.stats import gaussian_kde
from sklearn.preprocessing import MinMaxScaler		
import numpy as np
import pandas as pd
import numpy as np
from sklearn import preprocessing
from sklearn.ensemble import RandomForestRegressor
import matplotlib.pyplot as plt
import matplotlib
from sklearn.model_selection import train_test_split
from torch import optim
import torch.nn as nn
import torch.nn.functional as F
import torch
import torch.nn as nn			#


import numpy as np
import matplotlib.pyplot as plt		
os.environ["CUDA_VISIBLE_DEVICES"] = '0'


def computeCorrelation(X, Y):
    xBar = np.mean(X)
    yBar = np.mean(Y)
    SSR = 0
    varX = 0
    varY = 0
    for i in range(0, len(X)):
        diffXXBar = X[i] - xBar
        diffYYBar = Y[i] - yBar
        SSR += (diffXXBar * diffYYBar)
        varX += diffXXBar ** 2
        varY += diffYYBar ** 2

    SST = math.sqrt(varX * varY)
    rsq = (SSR / SST) ** 2
    return rsq
class r2_loss(nn.Module):
    def __init__(self, t1, t2, beta):
        super(r2_loss, self).__init__()
        self.t1 = t1
        self.t2 = t2
        self.beta = beta
        return

    def forward(self, anchor, positive, negative):
        matched = torch.pow(F.pairwise_distance(anchor, positive), 2)
        mismatched = torch.pow(F.pairwise_distance(anchor, negative), 2)
        part_1 = torch.clamp(matched - mismatched, min=self.t1)
        part_2 = torch.clamp(matched, min=self.t2)
        dist_hinge = part_1 + self.beta * part_2
        loss = torch.mean(dist_hinge)
        return loss

class r_2loss(nn.Module):
    def __init__(self):
        super(r_2loss, self).__init__()

    def forward(self, X, Y):
        xBar = np.mean(X)
        yBar = np.mean(Y)
        SSR = 0
        varX = 0
        varY = 0
        mse_loss = 0
        for i in range(0, len(X)):
            diffXXBar = X[i] - xBar
            diffYYBar = Y[i] - yBar
            SSR += (diffXXBar * diffYYBar)
            varX += diffXXBar ** 2
            varY += diffYYBar ** 2
        print(SSR)
        SST = math.sqrt(varX * varY)

        mse_loss = (SSR / SST) ** 2
        return mse_loss


def scatter_plot(TureValues,PredictValues):

    xxx = [-100.5,500.5]
    yyy = [-100.5,500.5]
    print(len(TureValues))
    T_m=round(max(TureValues))
    P_m=round(max(PredictValues))
    xy = np.vstack([TureValues, PredictValues])
    z = gaussian_kde(xy)(xy)

    plt.figure()
    font1 = {'family': 'Times New Roman',
             'weight': 'bold',
             'size': 18,
             }

    plt.subplots_adjust(left=0.15, right=0.95, top=0.95, bottom=0.15)
    plt.tick_params(labelsize=16)
    plt.plot(xxx , yyy , c='0' , linewidth=1 , linestyle=':' , marker='.' , alpha=0.4)
    # plt.scatter(TureValues , PredictValues , s=20 , c='r' , edgecolors='k' , marker='o' , alpha=0.8,cmap='Spectral')
    plt.scatter(TureValues, PredictValues, s=20, c=z,cmap='Spectral')  
    plt.xlim((0,300))   
    plt.ylim((0,300))
    # plt.figure(figsize=(10, 8), dpi=100)
    plt.xlabel("Actual value (μg/m³)",font1)

    plt.ylabel("Predictive value (μg/m³)",font1)
    plt.title('')
    plt.show()


feature=pd.read_csv("data.csv")
feature

label=feature["PM25"]
label=np.array(label)

feature=feature.drop("PM25",axis=1)
data=np.array(feature)

data=preprocessing.StandardScaler().fit_transform(data)
data
train_data=[]
train_label=[]
test_data=[]
test_label=[]
for i in range(len(data)):
    if(i%5==0):
        test_data.append(data[i])
        test_label.append(label[i])
    else:
        train_data.append(data[i])
        train_label.append(label[i])

train_data=torch.tensor(np.array(train_data),dtype=float,requires_grad=True).to(torch.float32)
train_label=torch.tensor(np.array(train_label),dtype=float,requires_grad=True).to(torch.float32)
test_data=torch.tensor(np.array(test_data),dtype=float,requires_grad=True).to(torch.float32)
test_label=torch.tensor(np.array(test_label),dtype=float,requires_grad=True).to(torch.float32)
act_t=[]
pre_t=[]


class housing_NN(nn.Module):
    def __init__(self):
        super().__init__()
        self.hidden1=nn.Linear(6,128)
        self.hidden2=nn.Linear(128,256)
        self.hidden3=nn.Linear(256,256)
        self.out=nn.Linear(256,1)
        self.drop=nn.Dropout(0.05)
    def forward(self,x):
        x=F.relu(self.hidden1(x))
        x=self.drop(x)
        x=F.relu(self.hidden2(x))
        x=self.drop(x)
        x=F.relu(self.hidden3(x))
        x=self.drop(x)
        x=self.out(x)
        x=x.squeeze(-1)
        return x
net=housing_NN()
def fit(epoches,model,loss_func,opt,batch_size,data,label,t_data,t_label):
    act_q = []
    pre_q = []
    pre_w = []  
    act_w = []
    pre_e = []  
    act_e = []
    for epoch in range(epoches):
        for start in range(0,len(data),batch_size):
            if start+batch_size<=len(data):
                end=start+batch_size
            else:
                end=len(data)
            x=data[start:end]
            y=label[start:end]
            x=x.cuda()
            y=y.cuda()
            model.train()
            pre = model(x)
            pre = pre.cuda()
            pre_c =pre.cpu()
            y_c = y.cpu()
            loss=loss_func(pre_c,y_c)
            # loss=computeCorrelation(pre, y)
            opt.zero_grad()
            loss.backward()
            opt.step()
            rt_pre = pre.cpu()
            r_pre = rt_pre.detach().numpy()
            rt_y = y.cpu()
            r_y =rt_y.detach().numpy()
            # print(len(r_y))
            rsquare = computeCorrelation(r_pre, r_y)
            print('MSE', mean_squared_error(r_y, r_pre))
            print('MAE', mean_absolute_error(r_y, r_pre))
        if epoch%500==0:
            for i in range(len(t_data)):
                p_q = my_model(t_data[i])
                pre_q.append(p_q.item())
                act_q.append(t_label[i].item())
            rst = computeCorrelation(pre_q, act_q)
            print('MSE', mean_squared_error(act_q, pre_q))
            print('MAE', mean_absolute_error(act_q, pre_q))
        
            checkpoint = {'model': my_model.state_dict(), 'optimizer': my_opt.state_dict(), \
                          'epoch': my_epoches, }
            torch.save(checkpoint, 'sgd12.26.pth')
            print(f"epoch:{epoch},loss:{loss},rsquare:{rsquare},rsquare:{rst}",)
        if rst>0.51:
        # if loss<15:

      
            for i in range(len(t_data)):
                p_w = my_model(t_data[i])
                pre_w.append(p_w.item())
                act_w.append(t_label[i].item())
   
            for i in range(len(data)):
                p_e = my_model(data[i])
                pre_e.append(p_e.item())
                act_e.append(label[i].item())

            # print(len(act_w))
            # print(len(pre_w))
            # print(len(act_w))
            rst = computeCorrelation(pre_w,act_w)
            rsquare= computeCorrelation(pre_e,act_e)
            print(f"epoch:{epoch},loss:{loss},rsquare:{rsquare},rsquare:{rst}")
            print("finish")
            torch.save(my_model,'b3.22.pth')
            scatter_plot(pre_w, act_w)
            scatter_plot(pre_e, act_e)
            break
    # return pre
my_epoches=80000
my_model=housing_NN()
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")  # 有没有GPU
my_model.to(device)
train_data,train_label = train_data.cuda() ,train_label.cuda()
test_data,test_label = test_data.cuda() ,test_label.cuda()

# my_loss_func=torch.nn.SmoothL1Loss()
my_loss_func=nn.MSELoss()
# my_loss_func=r_2loss()
# my_opt=optim.SGD(my_model.parameters(), lr=0.01, lambd=0.0001, alpha=0.75, t0=1000000.0, weight_decay=0)
# my_opt=optim.Adadelta(my_model.parameters(), lr=0.01)
my_opt=optim.NAdam(my_model.parameters(),lr=0.001)
my_batch_size=128
# pre_t = fit(my_epoches,my_model,my_loss_func,my_opt,my_batch_size,train_data,train_label)

fit(my_epoches,my_model,my_loss_func,my_opt,my_batch_size,train_data,train_label,test_data,test_label)
# array_pre = pre_t.detach().numpy()
# print(array_pre)

# scatter_plot(pre,act)
#
# computeCorrelation(pre, act)

pre=[]
act=[]
# for i in range(len(test_data)):
#     p=my_model(test_data[i])
#     pre.append(p.item())
#     act.append(test_label[i].item())
# rst = computeCorrelation(pre, act)
# print(rst)
# scatter_plot(pre,act)
# plt.figure(1)
# plt.plot(pre,color="r")
# plt.plot(act,color="b")
